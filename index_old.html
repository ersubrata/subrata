<!DOCTYPE html>
<html>
    <head>
        <title>SKYSCALE</title>
        <link rel="stylesheet" href="styles.css">
		<link rel="preconnect" href="https://fonts.googleapis.com">
		<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
		<link href="https://fonts.googleapis.com/css2?family=Readex+Pro:wght@160..700&display=swap" rel="stylesheet">	
		<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
        <style>
			 body {
				padding: 7%; /* Adding left and right margins */
				margin-bottom: 10%;
				font-size: 20px;
				overflow-x: hidden;
			}
            .container {
                display: grid;
                grid-template-columns: repeat(8, 1fr);
                gap: 20px;
            }
            .row {
                display: contents;
            }
            .item {
                padding: 20px;
                /* border: 1px solid #000; */
                text-align: center;
            }
			p{
				//background-color: darkgoldenrod;
				//color: cornsilk;
				margin: 10px;
				font-family: "Readex Pro", sans-serif;
				line-height: 1.5;
				align: justify;
			}
			
			figure {
				display: inline-block;
				text-align: justify;
				margin: 2%; /* adjust as needed */
				float: left;
				width: 40vw;
			}
			figure img {
				vertical-align: top;
				width: 100%;
				border-radius: 25px;
			}
			figure figcaption {
				float: left
				width: 40vw;
				font-family: monospace;
				font-size: 0.9em;
				font-weight: bold;
				color: 	#282828;
				margin: 1.61%
			}
			body{
				font-family: "Readex Pro", sans-serif;
				//background-color: #f0ebfc;
				background-image: url("background_image.jpg")
				
			}
			h2::first-letter{
				color: #3572EF;
				font-size: 1.5em;
			}
			footer {
			  position: fixed;
			  color: navy;
			  margin: 1% 0% 0% 0%;
			  left: 0;
			  bottom: 0;
			  width: 100%;
			  text-align: center;
			  background-color: #D2E0FB;
			  padding: 1% 0% 1% 0%;
			  border-radius: 20px  20px 0px 0px;
			}
        </style>
    </head>
    <body>

        <center><div class="pos_dev">
            <h1><span style="font-variant-caps: petite-caps; font-size:1.5em"><span style="color:#3572EF">S</span>ky<span style="color:#3572EF">S</span>cale</span>: A Radio Tomographic Approach Towards Scaling UAV Network Deployments</h1>            
            <p>Subrata Das and Ayon Chakraborty @ SENSE Lab, IIT Madras</p>
            <p>
                [<a href='' target="_blank">Datasets</a>]  
                [<a href='' target="_blank">Scripts</a>] 
                [<a href='' target="_blank">Full Paper</a>] 
                [<a href='' target='_blank'>Presentation Slides</a>]
            </p>
        </div></center>
        <div>
            <h3>Citations</h3>
            In case you use the data cite us via the following references:
            <pre style="background-color: lightyellow; padding: 3.14%; border-radius: 25px; font-family: courier; color:DimGray; overflow-x: scroll;">
<b>@inproceedings{ABC,
    title=<span style="text-wrap: wrap; color:cornflowerblue;">{SkyScale: A Radio Tomographic Approach Towards Scaling UAV Network Deployments}</span>,
    author={Subrata Das,  Ayon Chakraborty},
    booktitle={25th International Symposium on Theory, Algorithmic Foundations, and Protocol Design for Mobile Networks and Mobile Computing (MobiHoc 2024)},
    location={Athens, Greece},
    year={2024}
}    </b>
            </pre>    
        </div>
        <h3 style="text-align: center;">All Terains and the corresponding REM generated by SIONNA simulator</h3><br>

        <div class="container" style="background-color: #D2E0FB; margin:1%; padding: 3.14%; border-radius: 25px; font-family: courier; color:DimGray; overflow-x: scroll;">
            <div class="row">
                <div class="item"><a href = "https://www.cse.iitm.ac.in/~ayon/">
                        <img src="terrain_2.jpg" width="210vw">
                    </a>
                </div>
                <div class="item"><a href = "">
                        <img src="terrain_3.jpg" height="210vw" width="210vw">
                    </a>
                </div>
                <div class="item"><a href = "">
                        <img src="terrain_4.jpg" height="210vw" width="210vw">
                    </a>
                </div>
                <div class="item"><a href = "">
                        <img src="" height="210vw" width="210vw">
                    </a>
                </div>
                <div class="item"><a href = "">
                        <img src="" height="210vw" width="210vw">
                    </a>
                </div>
                <div class="item"><a href = "">
                        <img src="" height="210vw" width="210vw">
                    </a>
                </div>
                <div class="item"><a href = "">
                        <img src="" height="210vw" width="210vw">
                    </a>
                </div>
                <div class="item"><a href = "">
                        <img src="" height="210vw" width="210vw">
                    </a>
                </div>
            </div>
            <div class="row">
                <div class="item"><a href = "">
                        <img src="" height="210vw" width="210vw">
                    </a>
                </div>
                <div class="item"><a href = "">
                        <img src="TERR_3.jpg" height="210vw" width="210vw">
                    </a>
                </div>
                <div class="item"><a href = "">
                        <img src="" height="210vw" width="210vw">
                    </a>
                </div>
                <div class="item"><a href = "">
                        <img src="" height="210vw" width="210vw">
                    </a>
                </div>
                <div class="item"><a href = "">
                        <img src="" height="210vw" width="210vw">
                    </a>
                </div>
                <div class="item"><a href = "">
                        <img src="" height="210vw" width="210vw">
                    </a>
                </div>
                <div class="item"><a href = "">
                        <img src="" height="210vw" width="210vw">
                    </a>
                </div>
                <div class="item"><a href = "">
                        <img src="" height="210vw" width="210vw">
                    </a>
                </div>
            </div>
        </div>


        <div>
            <h2>Abstract</h2>
            <p>
                A critical requirement for deploying Unmanned Aerial Vehicle (UAV) based wireless networks is to position the
				UAV optimally in the aerial space, ensuring robust connectivity. Such optimal positioning requires the UAV to
				estimate the propagation loss for each ground terminal or user equipment (UE) across the aerial space‚Äì a mapping
				typically referred to as the Radio Environment Map(REM). Existing literature in this area primarily focuses on 
				improving the accuracy of REM estimation from sparse and noisy signal measurements at the UAV (e.g., by training
				deep learning models). However, the estimated REMs lose relevance as the UEs relocate, necessitating the UAV to
				collect fresh measurements to re-estimate the REMs. Such repetitive measurements make the deployment challenging
				to scale, particularly with a higher number of UEs or with UE mobility. In this paper, we propose SkyScale that 
				uses Radio Tomographic Imaging (RTI) to estimate the wireless attenuation characteristics of the underlying terrain.
				Such characteristics are fundamental properties of the terrain and are agnostic to UE locations, thus allowing us to
				estimate REMs for any arbitrary UE location. We evaluate SkyScale on our WiFi based UAV network testbed, traces from
				an LTE testbed, and realistic simulation studies. We demonstrate that our RTI based SkyScale saves measurement costs
				by 10√ó or more compared to state-of-the-art interpolation based schemes, making it highly scalable and seamlessly 
				adaptive to dynamic network conditions
            </p>            
        </div>
        
        <div>
            <!-- <embed src="/media/subrata/New Volume/Java_projects/first_project/SkyScale/RTI.pdf" type="application/pdf" width="600" height="500"> -->
			
			<figure>
				<img src="RTI.png" alt="Radion Tomographic Imaging System for Wireless Environment" width="40%">
				<figcaption>RTI schematic for SkyScale. The signal from each UE reaches the UAV traversing through a host of such voxels
					experiencing propagation loss. Each voxel contributes to the propagation loss determined by its attenuation coefcient -
					for instance, free space, foliage etc.
				</figcaption>
			</figure>
			
            <h2>RTI primer</h2>
            <p>
                Wireless signals get attenuated as it traverses along a medium and signifcantly so, as it passes through physical objects ‚Äì e.g, buildings,
				foliage etc. The extent of such attenuation depends on the length of path traversed by the sig nal and material properties (e.g.,
				permittivity) of the traversing medium itself. Towards setting up an analytical framework for RTI, we frst discretize the 3D space into ùêç
				volume elements or voxels each of dimension &delta; (resolution being &delta;). RTI estimates the volumetric image, X &in; &#8477;, where
				x<sub>i</sub> &in; X specifes the attenuation coefcient of the i<sup>th</sup> voxel. We choose an arbitrary origin in the region of interest
				and specify our 3D coordinate system where a voxel corresponds to a single unit along each dimension. Figure in left shows a schematic of the
				setup ‚Äì the UAV	collects RSS measurements for each UE along its trajectory.
            </p>
			<p>
				Let the k<sup>th</sup> UE, denoted by UE<sub>i</sub> be located at L<sub>ue</sub><sup>k</sup>. It is trivial to assume that the UAV is aware of
				the UE location. The trajectory of the UAV is represented as [L<sup>1</sup>, L<sup>2</sup>, L<sup>3</sup> ¬∑ ¬∑ ¬∑ ], where L<sup>n</sup> denotes 
				the L<sup>th</sup> voxel along the trajectory. The UAV‚Äôs trajectory forms a synthetic aperture where, at each voxel, it records the received
				signal strength (RSS) from the set of available UEs. In such a setup, let <b>M</b> denote the measurement matrix, where m<sub>n</sub><sup>k</sup>
				&in; <b>M</b> represents the RSS recorded for UE<sub>s</sub> at L<sup>n</sup>. For a given measurement m<sub>n</sub><sup>k</sup> the transmitter 
				and receiver being located at L<sub>ue</sub><sup>k</sup> and L<sup>n</sup> respectively, let V<sub>k,n</sub> denote the set of voxels traced by 
				the straight line connecting them. We model m<sub>n</sub><sup>k</sup>(i.e., the total propagation loss at L<sup>n</sup>) as a sum of the attenuation
				coefcients of the voxels in V<sub>k,n</sub>.
			</p>
			<center>
			<img src="equation1.png" alt="Path loss model" style="width: 20%;float: center;">
			</center>
			<p>For diÔ¨Äerent UEs, the set ùêµ,ùê†varies (depending on ùê© and adds	spatial diversity to the RSS measurements. Additionally, when a
				UE changes its location, say, from ùêµùê†ùê± to ùêµùê†ùê≤ we consider this to be	equivalent to a new UE at location ùêµùê†ùê≤ . We defne a projection matrix
				A ‚àà {0, 1}ùìóùê†, where ùê†is the total number of measurements in M and ùê†denotes the total number of voxels. Each row ai ‚àà {0, 1}ùê†(an
				ùê†-bit vector) corresponds to a single measurement from a specifc UE, where, aij = 1 if ùê†‚àà ùêµ,ùê¨ else aij = 0. Intuitively, each row of
				Aùìóùê†marks the voxels that contribute to the signal‚Äôs attenuation	corresponding to the measurement entry in the same row of M.
				Note that each row of A/M are independent and may correspond to any relevant UE (marked as ‚Äò‚àó‚Äô in ùêµ‚àó ‚àà M in eqn. 2) for which
				measurements are performed.
			</p>
			<center>
			<img src="RTI_matrix.jpg" alt="Radion Tomographic Imaging System for Wireless Environment" width = 900vw/>
			</center>
			<p>
			The system of linear equations shown above are our RTI equations, the solution to which is the volumetric attenuation image (X).
			</p>
			<p>
			<b>Inverse problem and ill-posedness.</b> Given A and X, it is straightforward to compute M, aka, the forward problem. Rather, RTI solves
			the inverse problem, which is to estimate X from the measurement set and the projection matrix (computed from location traces). Since
			the RSS measurements are typically contaminated with noise, hence we can solve for X in the least squares sense,
			</p>
			<p>
				The solution to eqn. 3 is equivalent to taking the Moore-Penrose Pseudoinverse on M, i.e., X&#770; = (A<sup>T</sup>A)<sup>-1</sup> However, A needs to
				be full-rank which may not always hold good. This renders the problem ill-posed, where even slight variations in the input M cause
				the solution ùõÜ to vary drastically. To contain the magnitude of	variation, a regularization term is added to eqn. 3, shown in eqn. 4,
			</p>
			<p>
			Eqn. 4 is referred as the generalized Tikhonov regularization and is a common tool for solving ill-posed inverse problems. ùê†> 0
			is a hyperparameter and ùê†denotes the regularization operator whose choice, as we show later, aÔ¨Äects the quality of the solution
			considerably.We can rewrite the sentence and as we have not shown any detailed results on the choice of ùêÆ Note that such regularized
			inversion can also be expressed in the least squares form as,
			</p>
			<p>
			SkyScale adopts the solution demonstrated by eqn. 5 for estimating the attenuation image
			</p>
        </div>
		<div>
		<h2>REM generation utilizing X</h2>
		<p>
			Equation 1 demonstrate the path loss at any particular possition, and to create the REM one can repeat the same process for each
			possition in the 3D space at a particular height (for one UE) which is nothing but the REM.
		</p>
		</div>
		<div>
		<figure>
		<img src="fig3.jpg" alt="Resource ">
		<figcaption>Benchmark results for computation time and runtime memory usage for running the vanilla RTI scheme on the UAV‚Äôs onboard Raspberry
			Pi computer and	a well provisioned laptop. Due to memory constraints, the onboard computer is not able to run the solution if the voxel	dimension is 
			less than 2.5 m.
		</figcaption>
		</figure>
		<h2>Challenges with conventional RTI</h2>
		<p>
			To calibrate the reader, we present some preliminary results on computational resource usage while
			running vanilla RTI algorithm for our testbed environment, a volume of 75 m√ó75 m√ó40 m. We vary the voxel dimension from 3.5 m
			down to 1 m and observe the computation time and the runtime memory usage for the UAV‚Äôs onboard computer (a Raspberry Pi
			4, 1.5 GHz clock with 8 GB main memory) and a ground station laptop computer (3 GHz clock with 16 GB main memory). As shown
			in figure left, the onboard computer is unable to run when the voxel dimension is lesser than 2.5 m		
		</p>
		<h2>		
		</div>
		<br/> <br/> <br/>
		<div>
		<h2>SkyScale System</h2>
		<p>
		<figure style="width: 60vw">
			<img src="skyscale_system.jpg" alt="Resource ">
			<figcaption>
				The diÔ¨Äerent stages of SkyScale. LC and RC indicate the left and right camera perspectives from the stereo cam. First
				the segments are identifed on which to perform the RTI. Second, measurements are taken covering the maximal number of
				segments and the attenuation image is compute. Next, for any given UE location the corresponding REM can be estimated.
			</figcaption>
		</figure>
		<h2>Dimensionality Reduction for RTI</h2>
		<p>
		As discussed in RTI primer, the attenuation image X &in; &#8477; eÔ¨Äectively captures the attenuation coefcient x<sub>i</sub> of each voxel
		for each of the	<b>N</b> voxels. EÔ¨Äectively, the vanilla RTI method solves this <b>N</b> dimensional problem. However, <b>N</b> can be very
		large depending upon the resolution &delta; and thus result in prohibitively heavy computational load (see above figure). We make use of the
		UAV‚Äôs stereoscopic imagery data to reduce such bloated dimensionality. In particular, we compute a pixel based depth map for the underlying
		terrain and perform image segmentation on the same. Such segments roughly identify regions with similar obstacle characteristics - for instance,
		areas with dense foliage, building tops, open spaces and so on. We use the Watershed algorithm [19] on the depth map to perform segmentation.
		SkyScale is agnostic to any specifc choice of the segmentation algorithm as long as it does not require site-specifc training and the segmentation
		has a low computational footprint.
		</p>
		<p>
		Segments in 3D space. Note that the above mentioned segments only identify 2D regions on the depth map. Voxels corresponding to such regions are 
		marked as occupied in all 2D slices that make up the 3D volume, stacked up from the ground level to the average height of that particular segment.
		Such voxels are grouped together and mapped to specifc 3D segments.
		</p>
		<p>
		</p>
		</div>
		<!--New Div-->
		<div>
		<figure style="width: 60vw">
			<img src="terr3_4.jpg" alt="Resource ">
			<figcaption>
				Height histograms for terrains Terr3 and Terr4, as obtained from the SRTM provided depth maps. Segmentation of
				the depth map is shown. The four rightmost plots on both rows present computed trajectories based on the gain matrix (Œ£).
				Total trajectory length for both case is 500 meters. The initial gain matrix is also shown in the background
				<!--fix for text getting cut-->
			</figcaption>
		</figure>
		<h2><span style="color:#3572EF">S</span>ky<span style="color:#3572EF">S</span>cale</span> trajectory planning</h2>
		<p>
		Given the limited Ô¨Çight time endurance of the UAV, it is critical to optimize the length of the measurement trajectory while improving
		the accuracy of the attenuation image. Let U denote the set of navigable voxel identifers where the UAV can Ô¨Çy and take measurements.
		Considering ùê†UEs in our system, we initialize the segment sets, Œ£ùê†for each voxel ùê†‚àà U as,
		</p>
		<center>
			<img src="equation_2.jpg" alt="Path loss model" style="width: 20%;float: center;">
			</center>
		<p>
		EÔ¨Äectively, |&Sigma;<sub>n</sub>|indicates the number of segments that can be ‚Äòseen‚Äô by the UAV from the ùêµ‚Ñé voxel, i.e., this ensures that such
		segments has non-zero column entries in the projection matrix A (|¬∑| is the set cardinality operator). We refer to the collection of all
		Œ£ùê†superimposed on the aerial as the gain matrix. SkyScale‚Äôs trajectory planning algorithm chooses a path, T (defned by a specifc voxel order),
		that maximizes the total number of intercepted segments while keeping the length minimal or upper bounded by a budget, ùêÆ Specifcally, SkyScale
		has the following goal.
		</p>
		<center>
			<img src="equation_3.jpg" alt="Path loss model" style="width: 40%;float: center;">
		</center>		
		<p>
		
		<figure style="width: 40vw">
			<img src="algorithm.jpg" alt="Resource ">
			<figcaption>
				Results related to Experiment 4. SkyScale makes the best out UE mobility to keep a stable performance, unlike SkyRAN.
				<!--fix for text getting cut-->
			</figcaption>
		</figure>
		T<sub>opt</sub> denotes the optimal trajectory with the total path length given by the function path_length() in eqnuation 3. Considering &Sigma; =
		{1, 2, ¬∑ ¬∑ ¬∑ , K} as the set of all segment identifers, and &Sigma;<sub>n</sub> &#8834; &Sigma;, &forall;n &in; <b>U</b> equation 3 reduces to a
		variation of the Set Cover or the Max-Coverage problem which is well-known to be NP-Hard. In the following, we propose a greedy heuristic, specifcally keeping
		the distance constraint in mind. The intuition is simple ‚Äì We intend to minimize the cost per ‚Äòunseen‚Äô segment, where the cost depends
		on the distance between the current (L<sup>curr</sup>) and the next voxel (see line 5 of Algorithm left).
		</p>
		<p>
		The UAV‚Äôs starting voxel in the aerial space, once it reaches
		the desired height, is denoted by L<sup>0</sup> and <b>U</b> denotes the set of navigable voxels. The total allocated distance budget is C. dist(L<sup>i</sup>, L<sup>j</sup>)
		computes the Euclidean distance between the voxels i and j whereas Bresenham-3D (L<sup>i</sup>, L<sup>j</sup>) enumerates the voxel path approximating the straight line path connecting voxels
		i and j. The distance threshold Dmin used in line 5 trades oÔ¨Ä between the exploration of unseen segments away from L<sup>curr</sup> versus exploitation of segments in the close
		proximity of L<sup>curr</sup> , for solving the RTI equations. In the algorithm given in left, uses the weighted version of the Greedy Set Cover, where the weight is determined by the distance
		from L<sup>curr</sup> to the next chosen voxel, L<sup>i</sup>. Additionally, note that the journey from L<sup>curr</sup> to L<sup>i</sup> encounters new segments enriching the explored pool of segments further.
		The weighted Greedy Set Cover is known to have an approximation ratio of the ùêµ‚Ñé Harmonic number, ùêµ = 1 + 1/2 + 1/3 + 1/4 ¬∑ ¬∑ ¬∑ + 1/n , i.e., T = T<sub>opt</sub>, where n= |U|.
		</p>
		</div>
		<div>
		<figure style="width: 40vw">
			<img src="result.jpg" alt="Resource ">
			<figcaption>
				Results related to Experiment 4. SkyScale makes the best out UE mobility to keep a stable performance, unlike SkyRAN.
				<!--fix for text getting cut-->
			</figcaption>
		</figure>
		<h2>Result supporting the long term advantange of <span style="color:#3572EF">S</span>ky<span style="color:#3572EF">S</span>cale</span></h2>
		<p>
		First, the UAV takes a Ô¨Çight with a budget of 500 secs that contains the average REM error for each of the sixteen UEs within 3 dB. For each
		of the next 100 seconds, every UE in the simulation moves randomly within the arena. In case of SkyRan (non-RTI), no new information is added to the
		original REM available at the zeroth second. However, even without any UAV movement, SkyScale leverages the mobility of the UEs and incorporates new
		measurements into the RTI framework. This is used to perform incremental updates to the attenuation image improving its accuracy. The SkyScale UAV
		seamlessly moves to the new optimal location. In fgure left, we show that SkyScale is able to restrict the REM error reasonably well to around 3‚Äì4 dB, some
		of the Ô¨Çuctuations are due to the AWGN noise introduced by the simulator.		
		</p>
		</div>
		<div>
		<figure style="width: 40vw">
			<img src="fig7.jpg" alt="Resource ">
			<figcaption>
				For an UE churn of 50%, SkyScale can maintain an average REM accuracy of 3 dB with ‚âà300 s worth of measurements.
				<!--fix for text getting cut-->
			</figcaption>
		</figure>
		<figure style="width: 40vw">
			<img src="fig8.jpg" alt="Resource ">
			<figcaption>
				Cumulative budget for an UE churn of 50%. The requirement of fresh measurements beyond a point is nil for
				SkyScale which bolsters its sustainability for longer term deployments.
				<!--fix for text getting cut-->
			</figcaption>
		</figure>
		<figure style="width: 40vw">
			<img src="alpha_error.jpg" alt="Resource ">
			<figcaption>
				SkyScale is able to predict the attenuation coefcient within an accuracy of 0.2 dB.
				<!--fix for text getting cut-->
			</figcaption>
		</figure>
		</div>
		<br><br><br><br><br><br><br><br><br><br><br><br><br><br>
    </body>
	<footer>Made with <i class="fa fa-heart" style="color: tomato; margin: 0% 0.16% 0% 0.16%;"></i> by Sense Lab, IIT Madras</footer>
</html> 

